services:
  micro-agent:
    #extra_hosts:
    #    - host.docker.internal:host-gateway
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - 5050:8000
    environment:
      - PORT=8000
      - OPENAI_API_BASE=${DMR_BASE_URL}/engines/llama.cpp/v1
      - OPENAI_API_KEY="tada"
      - MODEL_RUNNER_CHAT_MODEL=${MODEL_RUNNER_CHAT_MODEL}
    depends_on:
      - download-chat-model
      
  download-chat-model:
    provider:
      type: model
      options:
        model: ${MODEL_RUNNER_CHAT_MODEL}
